{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74b4a2e",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8329c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos los paquete necesarios:\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob ##New package learned\n",
    "import shutil ##New package learned   \n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a174e",
   "metadata": {},
   "source": [
    "# Extract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "455d4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_xlsx(ventas_file):\n",
    "    ''' Extrae los datos de un documento XLSX y devuele un DataFrame \n",
    "    IN: XLSX \n",
    "    OUT: DataFrame\n",
    "    '''\n",
    "\n",
    "    return pd.read_excel(ventas_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e85696cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_plano(ventas_file):\n",
    "    ''' Extrae los datos de un documento TXT, con separador \"|\" y devuele un DataFrame \n",
    "    IN: TXT \n",
    "    OUT: DataFrame\n",
    "    '''\n",
    "\n",
    "    return pd.read_csv(ventas_file, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f948a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_json(ventas_file):\n",
    "    ''' Extrae los datos de un documento JSON y devuele un DataFrame \n",
    "    IN: JSON \n",
    "    OUT: DataFrame\n",
    "    '''\n",
    "\n",
    "    return pd.read_json(ventas_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f1f5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv(ventas_file):\n",
    "    ''' Extrae los datos de un documento CSV y devuele un DataFrame \n",
    "    IN: CSV \n",
    "    OUT: DataFrame\n",
    "    '''\n",
    "\n",
    "    return pd.read_csv(ventas_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "753df220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    '''\n",
    "    Extraer datos de diferentes fuentes y generar un DataFrame conjunto:\n",
    "\n",
    "    IN: TXT, JSON, XLSX y CSV\n",
    "    OUT: DataFrame\n",
    "    '''\n",
    "    #Definimos un DataFrame que contendrá todos los datos:\n",
    "    total_sales = pd.DataFrame(columns=[\"id_venta\", \"fecha\", \"cliente\", \"producto\", \"precio\", \"cantidad\"])\n",
    "\n",
    "    #Identificar el formato de datos:\n",
    "    for file in os.listdir('dirty_data/'):\n",
    "        \n",
    "        if file[-5:] == \".xlsx\":\n",
    "            \n",
    "            xlsx_df = from_xlsx(\"dirty_data/\"+file)\n",
    "            total_sales = pd.concat([total_sales, xlsx_df], join='inner')\n",
    "        \n",
    "        elif file[-4:] == \".txt\":\n",
    "\n",
    "            txt_df = from_plano(\"dirty_data/\"+file)\n",
    "            total_sales = pd.concat([total_sales, txt_df], join='inner')\n",
    "        \n",
    "        elif file[-5:] == \".json\":\n",
    "            \n",
    "            json_df = from_json(\"dirty_data/\"+file)\n",
    "            total_sales = pd.concat([total_sales, json_df], join='inner')\n",
    "\n",
    "        elif file[-4:] == \".csv\":\n",
    "            \n",
    "            csv_df = from_csv(\"dirty_data/\"+file)\n",
    "            total_sales = pd.concat([total_sales, csv_df], join='inner')    \n",
    "\n",
    "\n",
    "    return total_sales #DataFrame total de los 4 archivos diferentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d3fba",
   "metadata": {},
   "source": [
    "# Transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1110d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df_2_transform):\n",
    "    '''\n",
    "    Limpiar el contenido del DataFrame total para que pueda ser cargado sin errores\n",
    "\n",
    "    IN: DataFrame, sucio\n",
    "    OUT: DataFrame, limpio\n",
    "    '''\n",
    "\n",
    "    #Transformar todos los valores NaN en \"0\", para poder ser procesados\n",
    "    df_clean = df_2_transform.fillna(0)\n",
    "\n",
    "    #Eliminar \"ERROR\"\n",
    "    df_clean.replace('ERROR', 0, inplace=True) ### Se ejecuta sin necesidad de reasignar el DataFrame\n",
    "    \n",
    "    #Eliminamos la columna \"id_venta\"\n",
    "    df_clean.drop(\"id_venta\", axis=1, inplace=True)\n",
    "    \n",
    "    #Normalizar columna \"cliente\"\n",
    "    df_clean[\"cliente\"] = df_clean[\"cliente\"].replace(0, 'Anonimo')\n",
    "    df_clean[\"cliente\"] = df_clean[\"cliente\"].str.strip() #********\n",
    "    df_clean[\"cliente\"] = df_clean[\"cliente\"].str.capitalize()\n",
    "\n",
    "    #Limpiar de precios negativos y cantidades 0\n",
    "    df_clean[\"precio\"] = df_clean[\"precio\"].astype(int)\n",
    "    df_clean[\"cantidad\"] = df_clean[\"cantidad\"].astype(int)\n",
    "\n",
    "    df_clean = df_clean[df_clean[\"precio\"] > 0]          #********   #Es más fácil hacer un filtrado por los registros que queremos conservar\n",
    "    df_clean = df_clean[df_clean[\"cantidad\"] > 0]        #********   #en vez de filtrar los registros que no queremos conservar y luego eliminarlos. \n",
    "\n",
    "\n",
    "    #Normalizara columna fecha\n",
    "    df_clean[\"fecha\"] = pd.to_datetime(df_clean[\"fecha\"], format='mixed')   #********\n",
    "\n",
    "\n",
    "    #Corregir el indice total\n",
    "    df_clean = df_clean.sort_values(\"fecha\")    #********\n",
    "    df_clean = df_clean.reset_index(drop=True)  #********\n",
    "    \n",
    "    #Creamos nuestro \"id_ventas\" correcto:\n",
    "    df_clean.insert(0, 'id_venta', range(1, len(df_clean)+1))\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419f831",
   "metadata": {},
   "source": [
    "# Load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eedbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(df_2_load):\n",
    "    '''\n",
    "    Limpiar el contenido del DataFrame total para que pueda ser cargado sin errores\n",
    "\n",
    "    IN: DataFrame, sucio\n",
    "    OUT: DataFrame, limpio\n",
    "    '''\n",
    "\n",
    "    #Cargar datos limpios en un documento CSV\n",
    "    df_2_load.to_csv('clean_data/sales_data.csv')\n",
    "\n",
    "\n",
    "    ###\n",
    "    #Base de datos:\n",
    "    ###\n",
    "\n",
    "    #Crear un DataFrame con los cliente.\n",
    "    df_clientes = df_2_load[\"cliente\"].drop_duplicates().reset_index(drop=True)\n",
    "    df_clientes.insert(0, 'id_cliente', range(1, len(df_clientes+1)))\n",
    "\n",
    "\n",
    "    #Crear un DataFrame con los artículos del stock.\n",
    "    df_productos = df_2_load[\"producto\"].drop_duplicates().reset_index(drop=True)\n",
    "    df_productos.insert(0, 'id_producto', range(1, len(df_clientes+1)))\n",
    "\n",
    "    #Cear engine de la base de datos\n",
    "    engine = create_engine('sqlite:///base_datos/bdd_ventas.sqlite')\n",
    "    #Crear las diferentes tablas de los DataFrame que tenemos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return df_2_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356828be",
   "metadata": {},
   "source": [
    "# Ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00916fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2h/vps3xzys1vj_n4wcjx7rptp40000gn/T/ipykernel_9459/916060948.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  total_sales = pd.concat([total_sales, txt_df], join='inner')\n",
      "/var/folders/2h/vps3xzys1vj_n4wcjx7rptp40000gn/T/ipykernel_9459/2740982635.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean = df_2_transform.fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          Mouse\n",
       "1        Monitor\n",
       "2        Teclado\n",
       "3         Cables\n",
       "4    Auriculares\n",
       "5         Router\n",
       "6      Altavoces\n",
       "7      Microfono\n",
       "8         Laptop\n",
       "9         Webcam\n",
       "Name: producto, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data = extract()\n",
    "\n",
    "data_cleaned = transform(extracted_data)\n",
    "\n",
    "#load(data_cleaned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
